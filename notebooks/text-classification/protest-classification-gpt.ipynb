{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protest Classification Using LLM\n",
    "In this notebook, the objective is to use a Language Model (LLM) to classify protests into predefined categories. The input data is sourced from ACLED. Each row represents a protest with multiple columns, with the most relevant for classification being the `notes` column, which provides a description of the protest.\n",
    "\n",
    "## Overview of Approach\n",
    "1. **LLM Family**: For this, we utilize the OpenAI family of `GPT` models.\n",
    "\n",
    "2. **Design Classification Prompt and Assess Performance**: Using a manually curated training dataset with labeled protests, we experiment with various prompting strategies and evaluate performance. We also examine the impact of the number of few-shot examples used on results.\n",
    "\n",
    "3. **Apply Classification to the Dataset**: Once the optimal prompting strategy and number of few-shot examples are determined, we apply the classification approach to the entire dataset. This involves using the refined prompt to categorize each protest event based on its description, ensuring consistency and accuracy across all entries.\n",
    "\n",
    "## Limitations \n",
    "1. **Cost**. It is expensive to run OpenAI models when you have many tokens. This classification task costed around $100\n",
    "2. **Not utilizing all examples** In order to reduce cost and processing time, we are not utilizing all available examples to perfom the classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import bokeh\n",
    "from bokeh.models import Tabs, TabPanel\n",
    "from bokeh.core.validation.warnings import EMPTY_LAYOUT, MISSING_RENDERERS\n",
    "from bokeh.plotting import show, output_notebook\n",
    "\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langchain\")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================\n",
    "# SETUP INPUT\n",
    "# ==================\n",
    "DIR_DATA =  Path.cwd().parents[1].joinpath(\"data\", \"conflict\")\n",
    "FILE_PROTESTS = DIR_DATA.joinpath(\"protests_iran_20160101_20241009.csv\")\n",
    "FILE_PROTESTS_CLASSIFIED = DIR_DATA.joinpath(\"protests_sample_acled_iran.csv\")\n",
    "FILE_PROTESTS_CLASSES = DIR_DATA.joinpath(\"protest_classification.csv\")\n",
    "FILE_PROTESTS_TRAINING = DIR_DATA.joinpath(\"protests-labeled-sample-training.csv\")\n",
    "\n",
    "# ==================\n",
    "# CLASSIFICATION \n",
    "# ==================\n",
    "PROP_TRAIN = 0.4\n",
    "NUM_EXAMPLES = 10\n",
    "SAMPLE_PROP = 0.5\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# For testing, classify only a portion of the documents\n",
    "SAMPLE_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PROTESTS_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Livelihood (Prices, jobs and salaries)    64\n",
       "Political/Security                        56\n",
       "Business and legal                        42\n",
       "Social                                    26\n",
       "Public service delivery                   25\n",
       "Climate and environment                   11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dunstanmatekenya/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/data/conflict/protest_classification.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_prot \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(FILE_PROTESTS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_prot_labels \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(FILE_PROTESTS_CLASSIFIED)\n\u001b[0;32m----> 3\u001b[0m df_tmp2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_PROTESTS_CLASSES\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dunstanmatekenya/Library/CloudStorage/OneDrive-WBG(2)/Data-Lab/iran-economic-monitoring/data/conflict/protest_classification.csv'"
     ]
    }
   ],
   "source": [
    "df_prot = pd.read_csv(FILE_PROTESTS, dtype=str)\n",
    "df_prot_labels = pd.read_csv(FILE_PROTESTS_CLASSIFIED)\n",
    "df_tmp2 = pd.read_csv(FILE_PROTESTS_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_code = dict(df_tmp2[[\"code\", \"description\"]].values)\n",
    "category_code = dict(df_tmp2[[\"code\", \"major_category\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prot_labels.rename(columns={'Classification code': \"code\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prot_labels['description'] = df_prot_labels.code.map(description_code)\n",
    "df_prot_labels['category'] = df_prot_labels.code.map(category_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_value_counts(\n",
    "    df, column, title=None, line_length=None, top_n=None, table_number=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Pretty prints the value counts of a specified column in a Pandas DataFrame,\n",
    "    with counts formatted with thousand separators, percentages, and cumulative percentages.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    column : str\n",
    "        The name of the column for which to calculate value counts.\n",
    "    title : str, optional\n",
    "        A title to print above the formatted output. If None, no title is printed.\n",
    "    line_length : int, optional\n",
    "        The length of the separator line. If None, it will be determined based on\n",
    "        the length of the title or default to 50 if no title is provided.\n",
    "    top_n : int, optional\n",
    "        The number of top categories to display. If None, all categories are displayed.\n",
    "    table_number : int, optional\n",
    "        The numeric value for the table number. If provided, the table number will be displayed as 'Table-X'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays a styled DataFrame with counts, percentages, and cumulative percentages.\n",
    "    \"\"\"\n",
    "    # Calculate the value counts and convert to DataFrame\n",
    "    count_df = pd.DataFrame(df[column].value_counts(normalize=False).reset_index())\n",
    "    count_df.columns = [\"Category\", \"Count\"]\n",
    "\n",
    "    # Add a percentage column\n",
    "    count_df[\"Percent\"] = (count_df[\"Count\"] / count_df[\"Count\"].sum()) * 100\n",
    "\n",
    "    # Add a cumulative percentage column\n",
    "    count_df[\"Cum. Percent\"] = count_df[\"Percent\"].cumsum()\n",
    "\n",
    "    # Limit the output to top_n categories if specified\n",
    "    if top_n:\n",
    "        count_df = count_df.head(top_n)\n",
    "\n",
    "    # Print the table number if provided\n",
    "    if table_number is not None:\n",
    "        print(f\"Table-{table_number}\")\n",
    "\n",
    "    # Determine the length of the line if line_length is not provided\n",
    "    if title:\n",
    "        if line_length is None:\n",
    "            line_length = max(\n",
    "                50, len(title) + 4\n",
    "            )  # Ensure at least 50 characters, or more based on the title\n",
    "\n",
    "        # Calculate padding to center the title\n",
    "        total_padding = line_length - len(title)\n",
    "        left_padding = total_padding // 2\n",
    "        right_padding = total_padding - left_padding\n",
    "\n",
    "        # Print the centered title with the \"=\" line\n",
    "        print(\"=\" * line_length)\n",
    "        print(\" \" * left_padding + title + \" \" * right_padding)\n",
    "        print(\"=\" * line_length)\n",
    "\n",
    "    # Display the styled DataFrame without index, formatting Count, Percent, and Cumulative Percent columns\n",
    "    display(\n",
    "        count_df.style.hide(axis=\"index\").format(\n",
    "            {\n",
    "                \"Count\": \"{:,.0f}\",  # Thousand separator for Count\n",
    "                \"Percent\": \"{:.2f}%\",  # Format Percent to 2 decimal places with a % symbol\n",
    "                \"Cum. Percent\": \"{:.2f}%\",  # Format Cumulative Percent to 2 decimal places with a % symbol\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Print footer or separator\n",
    "    print(\"-\" * line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "              Distribution of Protest Classes               \n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f9b72\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f9b72_level0_col0\" class=\"col_heading level0 col0\" >Category</th>\n",
       "      <th id=\"T_f9b72_level0_col1\" class=\"col_heading level0 col1\" >Count</th>\n",
       "      <th id=\"T_f9b72_level0_col2\" class=\"col_heading level0 col2\" >Percent</th>\n",
       "      <th id=\"T_f9b72_level0_col3\" class=\"col_heading level0 col3\" >Cum. Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row0_col0\" class=\"data row0 col0\" >Livelihood (Prices, jobs and salaries)</td>\n",
       "      <td id=\"T_f9b72_row0_col1\" class=\"data row0 col1\" >64</td>\n",
       "      <td id=\"T_f9b72_row0_col2\" class=\"data row0 col2\" >28.57%</td>\n",
       "      <td id=\"T_f9b72_row0_col3\" class=\"data row0 col3\" >28.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row1_col0\" class=\"data row1 col0\" >Political/Security</td>\n",
       "      <td id=\"T_f9b72_row1_col1\" class=\"data row1 col1\" >56</td>\n",
       "      <td id=\"T_f9b72_row1_col2\" class=\"data row1 col2\" >25.00%</td>\n",
       "      <td id=\"T_f9b72_row1_col3\" class=\"data row1 col3\" >53.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row2_col0\" class=\"data row2 col0\" >Business and legal</td>\n",
       "      <td id=\"T_f9b72_row2_col1\" class=\"data row2 col1\" >42</td>\n",
       "      <td id=\"T_f9b72_row2_col2\" class=\"data row2 col2\" >18.75%</td>\n",
       "      <td id=\"T_f9b72_row2_col3\" class=\"data row2 col3\" >72.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row3_col0\" class=\"data row3 col0\" >Social</td>\n",
       "      <td id=\"T_f9b72_row3_col1\" class=\"data row3 col1\" >26</td>\n",
       "      <td id=\"T_f9b72_row3_col2\" class=\"data row3 col2\" >11.61%</td>\n",
       "      <td id=\"T_f9b72_row3_col3\" class=\"data row3 col3\" >83.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row4_col0\" class=\"data row4 col0\" >Public service delivery</td>\n",
       "      <td id=\"T_f9b72_row4_col1\" class=\"data row4 col1\" >25</td>\n",
       "      <td id=\"T_f9b72_row4_col2\" class=\"data row4 col2\" >11.16%</td>\n",
       "      <td id=\"T_f9b72_row4_col3\" class=\"data row4 col3\" >95.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f9b72_row5_col0\" class=\"data row5 col0\" >Climate and environment</td>\n",
       "      <td id=\"T_f9b72_row5_col1\" class=\"data row5 col1\" >11</td>\n",
       "      <td id=\"T_f9b72_row5_col2\" class=\"data row5 col2\" >4.91%</td>\n",
       "      <td id=\"T_f9b72_row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ff55c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_value_counts(df_prot_labels, \"category\", \n",
    "title=\"Distribution of Protest Classes\", line_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prot_labels.to_csv(DIR_DATA.joinpath(\"protest-with-labels.csv\"), \n",
    "index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Zero Shot Classification Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Classification Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_5_classification(dataset, categories):\n",
    "    predictions = []\n",
    "    for note in dataset['notes']:\n",
    "        # Format the prompt with the note and available categories\n",
    "        prompt = prompt_template.format(categories=\", \".join(categories), note=note)\n",
    "        response = llm(prompt)\n",
    "        predictions.append(response.strip())\n",
    "    \n",
    "    dataset['gpt3_5_classification'] = predictions\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(dataset['category'], dataset['gpt3_5_classification'])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the examples into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/p4nvl2pj4gq2ks0j7qvrhwbh0000gp/T/ipykernel_96019/4000967764.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = df_prot_labels.groupby('category', group_keys=False).apply(lambda x: x.sample(frac=PROP_TRAIN,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((89, 6), (135, 6))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's perform a stratified split, ensuring that 80% of the examples from each category are used for training\n",
    "\n",
    "# Split the data while maintaining the distribution of categories\n",
    "train_df = df_prot_labels.groupby('category', group_keys=False).apply(lambda x: x.sample(frac=PROP_TRAIN, \n",
    "random_state=42))\n",
    "test_df = df_prot_labels.drop(train_df.index)\n",
    "\n",
    "(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           Train-Distribution of Protest Classes            \n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_13059\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_13059_level0_col0\" class=\"col_heading level0 col0\" >Category</th>\n",
       "      <th id=\"T_13059_level0_col1\" class=\"col_heading level0 col1\" >Count</th>\n",
       "      <th id=\"T_13059_level0_col2\" class=\"col_heading level0 col2\" >Percent</th>\n",
       "      <th id=\"T_13059_level0_col3\" class=\"col_heading level0 col3\" >Cum. Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row0_col0\" class=\"data row0 col0\" >Livelihood (Prices, jobs and salaries)</td>\n",
       "      <td id=\"T_13059_row0_col1\" class=\"data row0 col1\" >26</td>\n",
       "      <td id=\"T_13059_row0_col2\" class=\"data row0 col2\" >29.21%</td>\n",
       "      <td id=\"T_13059_row0_col3\" class=\"data row0 col3\" >29.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row1_col0\" class=\"data row1 col0\" >Political/Security</td>\n",
       "      <td id=\"T_13059_row1_col1\" class=\"data row1 col1\" >22</td>\n",
       "      <td id=\"T_13059_row1_col2\" class=\"data row1 col2\" >24.72%</td>\n",
       "      <td id=\"T_13059_row1_col3\" class=\"data row1 col3\" >53.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row2_col0\" class=\"data row2 col0\" >Business and legal</td>\n",
       "      <td id=\"T_13059_row2_col1\" class=\"data row2 col1\" >17</td>\n",
       "      <td id=\"T_13059_row2_col2\" class=\"data row2 col2\" >19.10%</td>\n",
       "      <td id=\"T_13059_row2_col3\" class=\"data row2 col3\" >73.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row3_col0\" class=\"data row3 col0\" >Public service delivery</td>\n",
       "      <td id=\"T_13059_row3_col1\" class=\"data row3 col1\" >10</td>\n",
       "      <td id=\"T_13059_row3_col2\" class=\"data row3 col2\" >11.24%</td>\n",
       "      <td id=\"T_13059_row3_col3\" class=\"data row3 col3\" >84.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row4_col0\" class=\"data row4 col0\" >Social</td>\n",
       "      <td id=\"T_13059_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "      <td id=\"T_13059_row4_col2\" class=\"data row4 col2\" >11.24%</td>\n",
       "      <td id=\"T_13059_row4_col3\" class=\"data row4 col3\" >95.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_13059_row5_col0\" class=\"data row5 col0\" >Climate and environment</td>\n",
       "      <td id=\"T_13059_row5_col1\" class=\"data row5 col1\" >4</td>\n",
       "      <td id=\"T_13059_row5_col2\" class=\"data row5 col2\" >4.49%</td>\n",
       "      <td id=\"T_13059_row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ff87bc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_value_counts(train_df, \"category\", \n",
    "title=\"Train-Distribution of Protest Classes\", line_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "            Test-Distribution of Protest Classes            \n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_18882\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_18882_level0_col0\" class=\"col_heading level0 col0\" >Category</th>\n",
       "      <th id=\"T_18882_level0_col1\" class=\"col_heading level0 col1\" >Count</th>\n",
       "      <th id=\"T_18882_level0_col2\" class=\"col_heading level0 col2\" >Percent</th>\n",
       "      <th id=\"T_18882_level0_col3\" class=\"col_heading level0 col3\" >Cum. Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row0_col0\" class=\"data row0 col0\" >Livelihood (Prices, jobs and salaries)</td>\n",
       "      <td id=\"T_18882_row0_col1\" class=\"data row0 col1\" >38</td>\n",
       "      <td id=\"T_18882_row0_col2\" class=\"data row0 col2\" >28.15%</td>\n",
       "      <td id=\"T_18882_row0_col3\" class=\"data row0 col3\" >28.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row1_col0\" class=\"data row1 col0\" >Political/Security</td>\n",
       "      <td id=\"T_18882_row1_col1\" class=\"data row1 col1\" >34</td>\n",
       "      <td id=\"T_18882_row1_col2\" class=\"data row1 col2\" >25.19%</td>\n",
       "      <td id=\"T_18882_row1_col3\" class=\"data row1 col3\" >53.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row2_col0\" class=\"data row2 col0\" >Business and legal</td>\n",
       "      <td id=\"T_18882_row2_col1\" class=\"data row2 col1\" >25</td>\n",
       "      <td id=\"T_18882_row2_col2\" class=\"data row2 col2\" >18.52%</td>\n",
       "      <td id=\"T_18882_row2_col3\" class=\"data row2 col3\" >71.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row3_col0\" class=\"data row3 col0\" >Social</td>\n",
       "      <td id=\"T_18882_row3_col1\" class=\"data row3 col1\" >16</td>\n",
       "      <td id=\"T_18882_row3_col2\" class=\"data row3 col2\" >11.85%</td>\n",
       "      <td id=\"T_18882_row3_col3\" class=\"data row3 col3\" >83.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row4_col0\" class=\"data row4 col0\" >Public service delivery</td>\n",
       "      <td id=\"T_18882_row4_col1\" class=\"data row4 col1\" >15</td>\n",
       "      <td id=\"T_18882_row4_col2\" class=\"data row4 col2\" >11.11%</td>\n",
       "      <td id=\"T_18882_row4_col3\" class=\"data row4 col3\" >94.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_18882_row5_col0\" class=\"data row5 col0\" >Climate and environment</td>\n",
       "      <td id=\"T_18882_row5_col1\" class=\"data row5 col1\" >7</td>\n",
       "      <td id=\"T_18882_row5_col2\" class=\"data row5 col2\" >5.19%</td>\n",
       "      <td id=\"T_18882_row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ff88da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_value_counts(test_df, \"category\", \n",
    "title=\"Test-Distribution of Protest Classes\", line_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample up to 5 examples from each category in the training set\n",
    "examples = []\n",
    "for category in train_df['category'].unique():\n",
    "    # Get all samples if fewer than 5 exist, otherwise take 5\n",
    "    category_samples = train_df[train_df['category'] == category].sample(\n",
    "        min(NUM_EXAMPLES, len(train_df[train_df['category'] == category])), random_state=42\n",
    "    )\n",
    "    examples.extend(category_samples[['notes', 'description', 'category']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a prompt template for classification, adding detailed examples\n",
    "classification_prompt_template = \"\"\"\n",
    "You are a highly intelligent assistant. Your task is to classify each document into one of the following categories:\n",
    "- Political/Security\n",
    "- Livelihood (Prices, jobs and salaries)\n",
    "- Public service delivery\n",
    "- Business and legal\n",
    "- Climate and environment\n",
    "- Social\n",
    "\n",
    "Each category has a description that helps explain its purpose.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Given the following document:\n",
    "{document}\n",
    "\n",
    "Based on the descriptions and the examples, which category does this document fall into? Please respond with one of the categories listed above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Format the examples for the prompt, including notes, descriptions, and categories\n",
    "formatted_examples = \"\\n\".join(\n",
    "    [\n",
    "        f\"Example {i+1}:\\nNotes: {example[0]}\\nDescription: {example[1]}\\nCategory: {example[2]}\"\n",
    "        for i, example in enumerate(examples)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Initialize the LLM (OpenAI in this case)\n",
    "llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.7)\n",
    "\n",
    "# Step 5: Create a prompt template using Langchain\n",
    "classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"document\", \"examples\"],\n",
    "    template=classification_prompt_template\n",
    ")\n",
    "\n",
    "# Step 6: Create a Langchain with the LLM and the classification prompt template\n",
    "classification_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=classification_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.23076923076923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      " Accuracy using model: gpt-3.5-turbo with 10 Examples\n",
      "=======================================================\n",
      "Accuracy: 87.41%\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with all the 'notes' column from test_df\n",
    "documents = test_df['notes'].tolist()\n",
    "\n",
    "# Classify each document and store results\n",
    "classifications = []\n",
    "for doc in documents:\n",
    "    result = classification_chain.run(document=doc, examples=formatted_examples)\n",
    "    # Clean up the result by removing the \"Category: \" prefix if it exists\n",
    "    cleaned_result = result.strip().replace(\"Category: \", \"\")\n",
    "    classifications.append(cleaned_result)  # Store the cleaned classification\n",
    "\n",
    "# Add the cleaned classification results to the DataFrame as a new column\n",
    "test_df['classification'] = classifications\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (test_df['classification'] == test_df['category']).sum()\n",
    "total_predictions = len(test_df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"=\"*55)\n",
    "print(f\" Accuracy using model: {OPENAI_MODEL} with {NUM_EXAMPLES} Examples\")\n",
    "print(\"=\"*55)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"-\"*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify All Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prot_sample = df_prot.sample(frac=SAMPLE_SIZE)\n",
    "# for index, row in df_prot_sample.iterrows():\n",
    "#     try:\n",
    "#         # Run classification for the \"notes\" column of the current row\n",
    "#         result = classification_chain.run(document=row['notes'], examples=formatted_examples)\n",
    "#         # Clean up the result by removing the \"Category: \" prefix if it exists\n",
    "#         cleaned_result = result.strip().replace(\"Category: \", \"\")\n",
    "#         # Store the cleaned classification in the \"classification\" column of the current row\n",
    "#         df_prot_sample.at[index, 'classification'] = cleaned_result\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row {index}: {e}\")\n",
    "#         df_prot_sample.at[index, 'classification'] = None  # Optionally, mark as None if there was an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_retry(document, examples, max_retries=1):\n",
    "    \"\"\"\n",
    "    Classifies the document, retrying if the initial classification is not in the specified categories.\n",
    "    \n",
    "    Parameters:\n",
    "    - document (str): The document to classify.\n",
    "    - examples (list): Examples to use for classification.\n",
    "    - max_retries (int): Number of retries allowed if classification is not in specified categories.\n",
    "\n",
    "    Returns:\n",
    "    - str: The final classification or 'Failed2Classify' if classification is unsuccessful.\n",
    "    \"\"\"\n",
    "    for _ in range(max_retries + 1):\n",
    "        result = classification_chain.run(document=document, examples=examples)\n",
    "        cleaned_result = result.strip().replace(\"Category: \", \"\")\n",
    "        \n",
    "        if cleaned_result in categories:\n",
    "            return cleaned_result  # Return if classification is in the categories\n",
    "    \n",
    "    # If classification failed after retries, label as \"Failed2Classify\"\n",
    "    return \"Failed2Classify\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify and ignore rows already classified in df_pro_sample\n",
    "# Also, classify when value in df_prot_sample == \"Failed2Classify\"\n",
    "for index, row in df_prot.iterrows():\n",
    "    # Check if this 'note' has already been classified in df_prot_sample\n",
    "    sample_classification = df_prot_sample.loc[\n",
    "        (df_prot_sample['event_date'] == row['event_date']) &\n",
    "        (df_prot_sample['source'] == row['source']) &\n",
    "        (df_prot_sample['admin1'] == row['admin1']) &\n",
    "        (df_prot_sample['admin2'] == row['admin2']) &\n",
    "        (df_prot_sample['admin3'] == row['admin3']) &\n",
    "        (df_prot_sample['notes'] == row['notes'])\n",
    "    ]['classification']\n",
    "\n",
    "    if sample_classification.notnull().any():\n",
    "        # Only reclassify if the current classification is \"Failed2Classify\"\n",
    "        if \"Failed2Classify\" in sample_classification.values:\n",
    "            # Run classification with retry mechanism\n",
    "            try:\n",
    "                classification = classify_with_retry(document=row['notes'], examples=formatted_examples)\n",
    "                df_prot.at[index, 'classification'] = classification\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                df_prot.at[index, 'classification'] = None  # Optionally, mark as None if there was an error\n",
    "        else:\n",
    "            continue  # Skip if already classified\n",
    "    else:\n",
    "        # Run classification if not in df_prot_sample\n",
    "        try:\n",
    "            classification = classify_with_retry(document=row['notes'], examples=formatted_examples)\n",
    "            df_prot.at[index, 'classification'] = classification\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            df_prot.at[index, 'classification'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on all columns except \"classification\"\n",
    "merged_df = df_prot.merge(\n",
    "    df_prot_sample,\n",
    "    on=['event_date', 'source', 'admin1', 'admin2', 'admin3', 'event_type', 'sub_event_type', \n",
    "        'interaction', 'fatalities', 'latitude', 'longitude', 'actor1', 'actor2', 'notes'],\n",
    "    how='left',\n",
    "    suffixes=('', '_sample')\n",
    ")\n",
    "\n",
    "# Update the \"classification\" column to prioritize non-\"Failed2Classify\" values from df_prot\n",
    "merged_df['classification'] = merged_df.apply(\n",
    "    lambda row: row['classification']\n",
    "    if pd.notnull(row['classification'])\n",
    "    else (row['classification_sample'] if row['classification_sample'] != \"Failed2Classify\" else \"Failed2Classify\"),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop the extra \"classification_sample\" column\n",
    "merged_df.drop(columns=['classification_sample'], inplace=True)\n",
    "\n",
    "# Drop duplicates based on all columns except \"classification\"\n",
    "merged_df.drop_duplicates(\n",
    "    subset=['event_date', 'source', 'admin1', 'admin2', 'admin3', 'event_type', 'sub_event_type', \n",
    "            'interaction', 'fatalities', 'latitude', 'longitude', 'actor1', 'actor2', 'notes'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Reset index for a clean merged dataframe\n",
    "merged_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape[0] == df_prot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "Livelihood (Prices, jobs and salaries)    13459\n",
       "Business and legal                         3369\n",
       "Social                                     3119\n",
       "Political/Security                         3109\n",
       "Public service delivery                     984\n",
       "Climate and environment                     915\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.classification.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# REMOVE CATEGORIES NOT IN THE AVAILABLE CLASSES\n",
    "# ===============================================\n",
    "categories = list(category_code.values())\n",
    "df_prot_sample['classification'] = df_prot_sample['classification'].apply(lambda x: x if x in categories else \"Failed2Classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(DIR_DATA.joinpath(\"protests-labeled-gpt.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "              Distribution of Labeled Protests              \n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_96b08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_96b08_level0_col0\" class=\"col_heading level0 col0\" >Category</th>\n",
       "      <th id=\"T_96b08_level0_col1\" class=\"col_heading level0 col1\" >Count</th>\n",
       "      <th id=\"T_96b08_level0_col2\" class=\"col_heading level0 col2\" >Percent</th>\n",
       "      <th id=\"T_96b08_level0_col3\" class=\"col_heading level0 col3\" >Cum. Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row0_col0\" class=\"data row0 col0\" >Livelihood (Prices, jobs and salaries)</td>\n",
       "      <td id=\"T_96b08_row0_col1\" class=\"data row0 col1\" >13,459</td>\n",
       "      <td id=\"T_96b08_row0_col2\" class=\"data row0 col2\" >53.93%</td>\n",
       "      <td id=\"T_96b08_row0_col3\" class=\"data row0 col3\" >53.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row1_col0\" class=\"data row1 col0\" >Business and legal</td>\n",
       "      <td id=\"T_96b08_row1_col1\" class=\"data row1 col1\" >3,369</td>\n",
       "      <td id=\"T_96b08_row1_col2\" class=\"data row1 col2\" >13.50%</td>\n",
       "      <td id=\"T_96b08_row1_col3\" class=\"data row1 col3\" >67.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row2_col0\" class=\"data row2 col0\" >Social</td>\n",
       "      <td id=\"T_96b08_row2_col1\" class=\"data row2 col1\" >3,119</td>\n",
       "      <td id=\"T_96b08_row2_col2\" class=\"data row2 col2\" >12.50%</td>\n",
       "      <td id=\"T_96b08_row2_col3\" class=\"data row2 col3\" >79.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row3_col0\" class=\"data row3 col0\" >Political/Security</td>\n",
       "      <td id=\"T_96b08_row3_col1\" class=\"data row3 col1\" >3,109</td>\n",
       "      <td id=\"T_96b08_row3_col2\" class=\"data row3 col2\" >12.46%</td>\n",
       "      <td id=\"T_96b08_row3_col3\" class=\"data row3 col3\" >92.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row4_col0\" class=\"data row4 col0\" >Public service delivery</td>\n",
       "      <td id=\"T_96b08_row4_col1\" class=\"data row4 col1\" >984</td>\n",
       "      <td id=\"T_96b08_row4_col2\" class=\"data row4 col2\" >3.94%</td>\n",
       "      <td id=\"T_96b08_row4_col3\" class=\"data row4 col3\" >96.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_96b08_row5_col0\" class=\"data row5 col0\" >Climate and environment</td>\n",
       "      <td id=\"T_96b08_row5_col1\" class=\"data row5 col1\" >915</td>\n",
       "      <td id=\"T_96b08_row5_col2\" class=\"data row5 col2\" >3.67%</td>\n",
       "      <td id=\"T_96b08_row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ff06570>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_value_counts(merged_df, \"classification\", \n",
    "\"Distribution of Labeled Protests\",line_length=60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DIR_DATA.joinpath(\"protests-labeled-all-gpt.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
